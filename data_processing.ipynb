{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SciSciNet Data Processing Pipeline\n",
        "\n",
        "This notebook processes SciSciNet data for network visualization:\n",
        "- Downloads data from Hugging Face\n",
        "- Filters data by institution and field\n",
        "- Generates network datasets for visualization\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Setup and Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import duckdb\n",
        "from huggingface_hub import hf_hub_download\n",
        "from dotenv import dotenv_values\n",
        "\n",
        "# Configuration\n",
        "config = dotenv_values()\n",
        "TOKEN = config.get(\"HF_TOKEN\")\n",
        "if not TOKEN:\n",
        "    raise ValueError(\n",
        "        \"HF_TOKEN not found in .env. Please create a .env file with HF_TOKEN=... \"\n",
        "    )\n",
        "\n",
        "REPO_ID = \"Northwestern-CSSI/sciscinet-v2\"\n",
        "DATA_DIR = \"dataset\"\n",
        "SAMPLE_DIR = os.path.join(DATA_DIR, \"sample\")\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "os.makedirs(SAMPLE_DIR, exist_ok=True)\n",
        "\n",
        "# Files to download\n",
        "FILES = [\n",
        "    \"sciscinet_papers.parquet\",\n",
        "    \"sciscinet_paperrefs.parquet\",\n",
        "    \"sciscinet_paper_author_affiliation.parquet\",\n",
        "    \"sciscinet_affiliations.parquet\",\n",
        "    \"sciscinet_paperfields.parquet\",\n",
        "    \"sciscinet_fields.parquet\",\n",
        "    \"sciscinet_author_details.parquet\"\n",
        "]\n",
        "\n",
        "# Processing configuration\n",
        "SCHOOL_NAME_EXACT = \"Beijing Normal University\"\n",
        "YEAR_FROM = 2015  # For full dataset (univ_cs_from2015_papers)\n",
        "NETWORK_YEAR_FROM = 2020  # For network datasets (citations, coauthors, papers)\n",
        "CS_FIELD_NAME = \"Computer science\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Download Data from Hugging Face\n",
        "\n",
        "Download required data files from the SciSciNet repository.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Already exists: sciscinet_papers.parquet\n",
            "âœ“ Already exists: sciscinet_paperrefs.parquet\n",
            "âœ“ Already exists: sciscinet_paper_author_affiliation.parquet\n",
            "âœ“ Already exists: sciscinet_affiliations.parquet\n",
            "âœ“ Already exists: sciscinet_paperfields.parquet\n",
            "âœ“ Already exists: sciscinet_fields.parquet\n",
            "âœ“ Already exists: sciscinet_author_details.parquet\n",
            "\n",
            "âœ“ All data files are ready.\n"
          ]
        }
      ],
      "source": [
        "# Download files from Hugging Face\n",
        "for filename in FILES:\n",
        "    local_path = os.path.join(DATA_DIR, filename)\n",
        "    if os.path.exists(local_path):\n",
        "        print(f\"âœ“ Already exists: {filename}\")\n",
        "        continue\n",
        "\n",
        "    print(f\"Downloading {filename}...\")\n",
        "    path = hf_hub_download(\n",
        "        repo_id=REPO_ID,\n",
        "        filename=filename,\n",
        "        token=TOKEN,\n",
        "        local_dir=DATA_DIR,\n",
        "        resume_download=True,\n",
        "        repo_type=\"dataset\",\n",
        "    )\n",
        "    print(f\"âœ“ Download completed: {os.path.basename(path)}\")\n",
        "\n",
        "print(\"\\nâœ“ All data files are ready.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Overview\n",
        "\n",
        "Inspect the structure and basic statistics of downloaded data files.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ“„ sciscinet_papers.parquet\n",
            "Shape: (249,803,279, 28)\n",
            "Columns: paperid, doi, year, date, doctype, cited_by_count, is_retracted, reference_count, citation_count, C3\n",
            "... and 18 more columns\n",
            "\n",
            "Sample data:\n",
            "       paperid   doi  year        date       doctype  cited_by_count  \\\n",
            "0  W2612738092  None  2002  2002-01-01       article               1   \n",
            "1  W2952574245  None  2009  2009-04-01  book-chapter               0   \n",
            "2  W3144847321  None  2006  2006-01-01  book-chapter               0   \n",
            "\n",
            "   is_retracted  reference_count  citation_count  C3  ...  WSB_Cinf  SB_B  \\\n",
            "0         False                0               4   4  ...       NaN   0.0   \n",
            "1         False                0               0   0  ...       NaN   NaN   \n",
            "2         False                0               0   0  ...       NaN   NaN   \n",
            "\n",
            "   SB_T  team_size  institution_count  patent_count  newsfeed_count  \\\n",
            "0     0          0                  0             0               0   \n",
            "1  <NA>          0                  0             0               0   \n",
            "2  <NA>          0                  0             0               0   \n",
            "\n",
            "   nct_count  nih_count  nsf_count  \n",
            "0          0          0          0  \n",
            "1          0          0          0  \n",
            "2          0          0          0  \n",
            "\n",
            "[3 rows x 28 columns]\n",
            "\n",
            "ðŸ“„ sciscinet_paperrefs.parquet\n",
            "Shape: (2,494,545,461, 5)\n",
            "Columns: citing_paperid, cited_paperid, year, ref_year, year_diff\n",
            "\n",
            "Sample data:\n",
            "  citing_paperid cited_paperid  year  ref_year  year_diff\n",
            "0      W61830335   W2037595686  2005      2001          4\n",
            "1      W61830335   W2065794083  2005      1997          8\n",
            "2      W61830335   W2089929309  2005      1997          8\n",
            "\n",
            "ðŸ“„ sciscinet_paper_author_affiliation.parquet\n",
            "Shape: (772,984,433, 5)\n",
            "Columns: paperid, author_position, authorid, institutionid, raw_affiliation_string\n",
            "\n",
            "Sample data:\n",
            "       paperid author_position     authorid institutionid  \\\n",
            "0  W2612738092           first  A5052637111                 \n",
            "1  W2612738092          middle  A5038562202                 \n",
            "2  W2612738092          middle  A5010431633   I4210088387   \n",
            "\n",
            "                              raw_affiliation_string  \n",
            "0                                               None  \n",
            "1                                               None  \n",
            "2  Heuristique et Diagnostic des SystÃ¨mes Complex...  \n",
            "\n",
            "ðŸ“„ sciscinet_affiliations.parquet\n",
            "Shape: (110,553, 10)\n",
            "Columns: institution_id, display_name, ror, homepage_url, country_code, type, h_index, productivity, avg_c10, avg_logc10\n",
            "\n",
            "Sample data:\n",
            "  institution_id                                 display_name        ror  \\\n",
            "0    I4210136388                   Carnot Institute Qualiment  032k75171   \n",
            "1    I4210163148  Korean Institute of Southeast Asian Studies  05gkpvg94   \n",
            "2    I4210145380               Westlake Porter Public Library  049kpjn93   \n",
            "\n",
            "                                        homepage_url country_code       type  \\\n",
            "0  https://www.instituts-carnot.eu/en/carnot-inst...           FR   facility   \n",
            "1                             http://www.kiseas.org/           KR  nonprofit   \n",
            "2                   https://www.westlakelibrary.org/           US    archive   \n",
            "\n",
            "   h_index  productivity  avg_c10  avg_logc10  \n",
            "0     <NA>          <NA>      NaN         NaN  \n",
            "1        0             1      0.0    0.000000  \n",
            "2        1             1      3.0    1.386294  \n",
            "\n",
            "ðŸ“„ sciscinet_paperfields.parquet\n",
            "Shape: (1,271,891,157, 3)\n",
            "Columns: paperid, fieldid, score_openalex\n",
            "\n",
            "Sample data:\n",
            "       paperid    fieldid  score_openalex\n",
            "0  W2612738092  C41008148        0.711943\n",
            "1  W2612738092  C31258907        0.639471\n",
            "2  W2612738092  C76155785        0.138308\n",
            "\n",
            "ðŸ“„ sciscinet_fields.parquet\n",
            "Shape: (303, 12)\n",
            "Columns: id, wikidata, display_name, level, description, works_count, cited_by_count, image_url, image_thumbnail_url, works_api_url\n",
            "... and 2 more columns\n",
            "\n",
            "Sample data:\n",
            "                               id                              wikidata  \\\n",
            "0   https://openalex.org/C1276947    https://www.wikidata.org/wiki/Q333   \n",
            "1  https://openalex.org/C86803240    https://www.wikidata.org/wiki/Q420   \n",
            "2  https://openalex.org/C71924100  https://www.wikidata.org/wiki/Q11190   \n",
            "\n",
            "  display_name  level                                        description  \\\n",
            "0    Astronomy      1  scientific study of celestial objects and phen...   \n",
            "1      Biology      0  scientific study of living things, especially ...   \n",
            "2     Medicine      0  field of study for diagnosing, treating and pr...   \n",
            "\n",
            "   works_count  cited_by_count  \\\n",
            "0      3473122        44060390   \n",
            "1     47304386       900557252   \n",
            "2     63716696       831526009   \n",
            "\n",
            "                                           image_url  \\\n",
            "0                                               None   \n",
            "1  https://upload.wikimedia.org/wikipedia/commons...   \n",
            "2  https://upload.wikimedia.org/wikipedia/commons...   \n",
            "\n",
            "                                 image_thumbnail_url  \\\n",
            "0                                               None   \n",
            "1  https://upload.wikimedia.org/wikipedia/commons...   \n",
            "2  https://upload.wikimedia.org/wikipedia/commons...   \n",
            "\n",
            "                                       works_api_url  \\\n",
            "0  https://api.openalex.org/works?filter=concepts...   \n",
            "1  https://api.openalex.org/works?filter=concepts...   \n",
            "2  https://api.openalex.org/works?filter=concepts...   \n",
            "\n",
            "                 updated_date    fieldid  \n",
            "0  2024-12-30T10:44:38.778686   C1276947  \n",
            "1  2024-12-29T13:17:49.537508  C86803240  \n",
            "2  2024-12-29T14:20:15.607400  C71924100  \n",
            "\n",
            "ðŸ“„ sciscinet_author_details.parquet\n",
            "Shape: (100,418,971, 9)\n",
            "Columns: authorid, orcid, display_name, display_name_alternatives, works_count, cited_by_count, last_known_institution, works_api_url, updated_date\n",
            "\n",
            "Sample data:\n",
            "      authorid orcid  display_name display_name_alternatives  works_count  \\\n",
            "0  A5074835999  None    J Millgate            [\"J Millgate\"]            1   \n",
            "1  A5044393500  None  Random Cloud          [\"Random Cloud\"]            1   \n",
            "2  A5093992040  None   Rick Pender           [\"Rick Pender\"]            1   \n",
            "\n",
            "   cited_by_count last_known_institution  \\\n",
            "0              55                   None   \n",
            "1              54                   None   \n",
            "2              38                   None   \n",
            "\n",
            "                                       works_api_url  \\\n",
            "0  https://api.openalex.org/works?filter=author.i...   \n",
            "1  https://api.openalex.org/works?filter=author.i...   \n",
            "2  https://api.openalex.org/works?filter=author.i...   \n",
            "\n",
            "                 updated_date  \n",
            "0  2024-07-17T18:27:20.433379  \n",
            "1  2024-07-17T20:37:44.694879  \n",
            "2  2024-07-17T16:50:57.644609  \n"
          ]
        }
      ],
      "source": [
        "# Connect to DuckDB\n",
        "con = duckdb.connect()\n",
        "\n",
        "# Inspect each file\n",
        "for filename in FILES:\n",
        "    path = os.path.join(DATA_DIR, filename)\n",
        "    print(f\"\\nðŸ“„ {filename}\")\n",
        "    \n",
        "    n_rows = con.execute(f\"SELECT COUNT(*) FROM read_parquet('{path}')\").fetchone()[0]\n",
        "    schema = con.execute(f\"DESCRIBE SELECT * FROM read_parquet('{path}')\").fetchdf()\n",
        "    n_cols = len(schema)\n",
        "    \n",
        "    print(f\"Shape: ({n_rows:,}, {n_cols})\")\n",
        "    print(f\"Columns: {', '.join(schema['column_name'].tolist()[:10])}\")\n",
        "    if n_cols > 10:\n",
        "        print(f\"... and {n_cols - 10} more columns\")\n",
        "    \n",
        "    # Show sample data\n",
        "    sample = con.execute(f\"SELECT * FROM read_parquet('{path}') LIMIT 3\").fetchdf()\n",
        "    print(\"\\nSample data:\")\n",
        "    print(sample)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Create Base Views\n",
        "\n",
        "Set up DuckDB views for efficient data access.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Base views created\n"
          ]
        }
      ],
      "source": [
        "# Define file paths\n",
        "PAPERS = os.path.join(DATA_DIR, \"sciscinet_papers.parquet\")\n",
        "PAA = os.path.join(DATA_DIR, \"sciscinet_paper_author_affiliation.parquet\")\n",
        "AFF = os.path.join(DATA_DIR, \"sciscinet_affiliations.parquet\")\n",
        "PF = os.path.join(DATA_DIR, \"sciscinet_paperfields.parquet\")\n",
        "FIELDS = os.path.join(DATA_DIR, \"sciscinet_fields.parquet\")\n",
        "REFS = os.path.join(DATA_DIR, \"sciscinet_paperrefs.parquet\")\n",
        "AUTHOR_DETAILS = os.path.join(DATA_DIR, \"sciscinet_author_details.parquet\")\n",
        "\n",
        "# Create views\n",
        "con.execute(f\"CREATE OR REPLACE VIEW papers AS SELECT * FROM read_parquet('{PAPERS}');\")\n",
        "con.execute(f\"CREATE OR REPLACE VIEW paa AS SELECT paperid, authorid, institutionid, author_position FROM read_parquet('{PAA}');\")\n",
        "con.execute(f\"CREATE OR REPLACE VIEW aff AS SELECT institution_id, display_name FROM read_parquet('{AFF}');\")\n",
        "con.execute(f\"CREATE OR REPLACE VIEW pfields AS SELECT paperid, fieldid FROM read_parquet('{PF}');\")\n",
        "con.execute(f\"CREATE OR REPLACE VIEW fields AS SELECT fieldid, display_name, level FROM read_parquet('{FIELDS}');\")\n",
        "con.execute(f\"CREATE OR REPLACE VIEW refs AS SELECT * FROM read_parquet('{REFS}');\")\n",
        "con.execute(f\"CREATE OR REPLACE VIEW author_details AS SELECT * FROM read_parquet('{AUTHOR_DETAILS}');\")\n",
        "\n",
        "print(\"âœ“ Base views created\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Identify Target Institution\n",
        "\n",
        "Match the target institution (Beijing Normal University) from the affiliations table.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Institution matched: Beijing Normal University -> I25254941\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<_duckdb.DuckDBPyConnection at 0x10a623bb0>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find institution ID\n",
        "inst_df = con.execute(\"\"\"\n",
        "    SELECT DISTINCT institution_id\n",
        "    FROM aff\n",
        "    WHERE display_name = ?\n",
        "\"\"\", [SCHOOL_NAME_EXACT]).fetchdf()\n",
        "\n",
        "if len(inst_df) != 1:\n",
        "    raise ValueError(f\"Institution match error: {SCHOOL_NAME_EXACT} -> {len(inst_df)} matches found\")\n",
        "\n",
        "MY_INST_ID = inst_df.iloc[0][\"institution_id\"]\n",
        "print(f\"âœ“ Institution matched: {SCHOOL_NAME_EXACT} -> {MY_INST_ID}\")\n",
        "\n",
        "# Create table for filtering\n",
        "con.execute(\"CREATE OR REPLACE TABLE my_inst AS SELECT ?::VARCHAR AS institution_id\", [MY_INST_ID])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Identify Computer Science Field\n",
        "\n",
        "Match the Computer Science field ID from the fields table.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Field matched: Computer science -> C41008148\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8897a220df284ccb96b3e76432aeb69d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<_duckdb.DuckDBPyConnection at 0x10a623bb0>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find Computer Science field ID\n",
        "cs_df = con.execute(\"\"\"\n",
        "    SELECT DISTINCT fieldid\n",
        "    FROM fields\n",
        "    WHERE display_name = ?\n",
        "\"\"\", [CS_FIELD_NAME]).fetchdf()\n",
        "\n",
        "if len(cs_df) != 1:\n",
        "    raise ValueError(f\"Field match error: '{CS_FIELD_NAME}' -> {len(cs_df)} matches found\")\n",
        "\n",
        "CS_FIELD_ID = cs_df.iloc[0][\"fieldid\"]\n",
        "print(f\"âœ“ Field matched: {CS_FIELD_NAME} -> {CS_FIELD_ID}\")\n",
        "\n",
        "# Create table for filtering\n",
        "con.execute(\"CREATE OR REPLACE TABLE cs_field_ids AS SELECT ?::VARCHAR AS fieldid\", [CS_FIELD_ID])\n",
        "\n",
        "# Create CS papers set\n",
        "con.execute(\"\"\"\n",
        "    CREATE OR REPLACE TABLE cs_papers AS\n",
        "    SELECT DISTINCT pfields.paperid\n",
        "    FROM pfields\n",
        "    JOIN cs_field_ids USING(fieldid);\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Generate Citation Network Data (2020+)\n",
        "\n",
        "Create internal citation network data (papers citing other papers within the same dataset) from 2020 onwards.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5f0d291d41f74274aa03f43f11e970d8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ citations_5y_internal: 6,868 rows\n",
            "ðŸ’¾ Saved: dataset/sample/citations_5y_internal.parquet\n"
          ]
        }
      ],
      "source": [
        "# Generate internal citations (both citing and cited papers are in our dataset and from 2020+)\n",
        "con.execute(f\"\"\"\n",
        "    CREATE OR REPLACE TABLE citations_5y_internal AS\n",
        "    WITH univ_cs_papers_2020 AS (\n",
        "        SELECT DISTINCT p.paperid, p.year\n",
        "        FROM papers p\n",
        "        JOIN paa ON p.paperid = paa.paperid\n",
        "        JOIN my_inst mi ON paa.institutionid = mi.institution_id\n",
        "        JOIN cs_papers csp ON p.paperid = csp.paperid\n",
        "        WHERE p.year >= {NETWORK_YEAR_FROM}\n",
        "    )\n",
        "    SELECT \n",
        "        r.citing_paperid AS citing_paperid,\n",
        "        r.cited_paperid AS cited_paperid,\n",
        "        p.year AS year\n",
        "    FROM refs r\n",
        "    JOIN univ_cs_papers_2020 p ON r.citing_paperid = p.paperid\n",
        "    WHERE r.cited_paperid IN (SELECT paperid FROM univ_cs_papers_2020);\n",
        "\"\"\")\n",
        "\n",
        "# Export\n",
        "OUT_CITATIONS = os.path.join(SAMPLE_DIR, \"citations_5y_internal.parquet\")\n",
        "con.execute(f\"COPY citations_5y_internal TO '{OUT_CITATIONS}' (FORMAT PARQUET);\")\n",
        "\n",
        "n_citations = con.execute(\"SELECT COUNT(*) FROM citations_5y_internal\").fetchone()[0]\n",
        "print(f\"âœ“ citations_5y_internal: {n_citations:,} rows\")\n",
        "print(f\"ðŸ’¾ Saved: {OUT_CITATIONS}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Generate Coauthor Network Data (2020+)\n",
        "\n",
        "Create coauthor relationship data from 2020 onwards.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fbfc6a25d00d401bb8e6b0129ea9feb0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ coauthor_details_5y: 30,806 rows\n",
            "ðŸ’¾ Saved: dataset/sample/coauthor_details_5y.parquet\n"
          ]
        }
      ],
      "source": [
        "# Generate coauthor details (paperid, authorid, author_position, year) - only 2020+\n",
        "con.execute(f\"\"\"\n",
        "    CREATE OR REPLACE TABLE coauthor_details_5y AS\n",
        "    WITH univ_cs_papers_2020 AS (\n",
        "        SELECT DISTINCT p.paperid, p.year\n",
        "        FROM papers p\n",
        "        JOIN paa ON p.paperid = paa.paperid\n",
        "        JOIN my_inst mi ON paa.institutionid = mi.institution_id\n",
        "        JOIN cs_papers csp ON p.paperid = csp.paperid\n",
        "        WHERE p.year >= {NETWORK_YEAR_FROM}\n",
        "    )\n",
        "    SELECT \n",
        "        paa.paperid,\n",
        "        paa.authorid,\n",
        "        paa.author_position,\n",
        "        p.year\n",
        "    FROM paa\n",
        "    JOIN univ_cs_papers_2020 p ON paa.paperid = p.paperid\n",
        "    JOIN my_inst mi ON paa.institutionid = mi.institution_id;\n",
        "\"\"\")\n",
        "\n",
        "# Export\n",
        "OUT_COAUTHORS = os.path.join(SAMPLE_DIR, \"coauthor_details_5y.parquet\")\n",
        "con.execute(f\"COPY coauthor_details_5y TO '{OUT_COAUTHORS}' (FORMAT PARQUET);\")\n",
        "\n",
        "n_coauthors = con.execute(\"SELECT COUNT(*) FROM coauthor_details_5y\").fetchone()[0]\n",
        "print(f\"âœ“ coauthor_details_5y: {n_coauthors:,} rows\")\n",
        "print(f\"ðŸ’¾ Saved: {OUT_COAUTHORS}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Generate Author Dataset (2020+)\n",
        "\n",
        "Create author information dataset for authors in the filtered papers from 2020 onwards.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "af5b3eb3f8c14a5698e4804d75d67ee5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ authors_university_5y_cs: 12,700 rows\n",
            "ðŸ’¾ Saved: dataset/sample/authors_university_5y_cs.parquet\n"
          ]
        }
      ],
      "source": [
        "# Get unique authors from coauthor details\n",
        "con.execute(\"\"\"\n",
        "    CREATE OR REPLACE TABLE authors_university_5y_cs AS\n",
        "    SELECT DISTINCT\n",
        "        ad.authorid,\n",
        "        ad.display_name AS author_name,\n",
        "        ad.orcid,\n",
        "        ad.works_count,\n",
        "        ad.cited_by_count,\n",
        "        paa.institutionid,\n",
        "        aff.display_name AS institution_name\n",
        "    FROM coauthor_details_5y cad\n",
        "    JOIN author_details ad ON cad.authorid = ad.authorid\n",
        "    JOIN paa ON cad.paperid = paa.paperid AND cad.authorid = paa.authorid\n",
        "    JOIN aff ON paa.institutionid = aff.institution_id\n",
        "    WHERE paa.institutionid = ?::VARCHAR;\n",
        "\"\"\", [MY_INST_ID])\n",
        "\n",
        "# Export\n",
        "OUT_AUTHORS = os.path.join(SAMPLE_DIR, \"authors_university_5y_cs.parquet\")\n",
        "con.execute(f\"COPY authors_university_5y_cs TO '{OUT_AUTHORS}' (FORMAT PARQUET);\")\n",
        "\n",
        "n_authors = con.execute(\"SELECT COUNT(*) FROM authors_university_5y_cs\").fetchone()[0]\n",
        "print(f\"âœ“ authors_university_5y_cs: {n_authors:,} rows\")\n",
        "print(f\"ðŸ’¾ Saved: {OUT_AUTHORS}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Generate Papers Dataset (2020+)\n",
        "\n",
        "Create papers dataset for the filtered set from 2020 onwards.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e14a6b85bc94f109fe19657b01dfae5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ papers_university_5y_cs: 13,310 rows\n",
            "ðŸ’¾ Saved: dataset/sample/papers_university_5y_cs.parquet\n"
          ]
        }
      ],
      "source": [
        "# Papers from 2020 onwards\n",
        "con.execute(f\"\"\"\n",
        "    CREATE OR REPLACE TABLE papers_university_5y_cs AS\n",
        "    SELECT DISTINCT p.*\n",
        "    FROM papers p\n",
        "    JOIN paa ON p.paperid = paa.paperid\n",
        "    JOIN my_inst mi ON paa.institutionid = mi.institution_id\n",
        "    JOIN cs_papers csp ON p.paperid = csp.paperid\n",
        "    WHERE p.year >= {NETWORK_YEAR_FROM};\n",
        "\"\"\")\n",
        "\n",
        "# Export\n",
        "OUT_PAPERS = os.path.join(SAMPLE_DIR, \"papers_university_5y_cs.parquet\")\n",
        "con.execute(f\"COPY papers_university_5y_cs TO '{OUT_PAPERS}' (FORMAT PARQUET);\")\n",
        "\n",
        "n_papers = con.execute(\"SELECT COUNT(*) FROM papers_university_5y_cs\").fetchone()[0]\n",
        "print(f\"âœ“ papers_university_5y_cs: {n_papers:,} rows\")\n",
        "print(f\"ðŸ’¾ Saved: {OUT_PAPERS}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Generate University CS Papers Dataset (2015+)\n",
        "\n",
        "Create a filtered dataset containing all papers from the target institution in Computer Science from 2015 onwards.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c4edc5b01f0140e79bbf19bd480ba5cf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Created and exported univ_cs_from2015_papers: 20,770 rows\n",
            "ðŸ’¾ Saved: dataset/sample/univ_cs_from2015_papers.parquet\n"
          ]
        }
      ],
      "source": [
        "# Create and export univ_cs_from2015_papers table\n",
        "con.execute(f\"\"\"\n",
        "    CREATE OR REPLACE TABLE univ_cs_from2015_papers AS\n",
        "    SELECT DISTINCT p.*\n",
        "    FROM papers p\n",
        "    JOIN paa ON p.paperid = paa.paperid\n",
        "    JOIN my_inst mi ON paa.institutionid = mi.institution_id\n",
        "    JOIN cs_papers csp ON p.paperid = csp.paperid\n",
        "    WHERE p.year >= {YEAR_FROM};\n",
        "\"\"\")\n",
        "\n",
        "# Export\n",
        "OUT = os.path.join(SAMPLE_DIR, \"univ_cs_from2015_papers.parquet\")\n",
        "con.execute(f\"COPY univ_cs_from2015_papers TO '{OUT}' (FORMAT PARQUET);\")\n",
        "\n",
        "# Statistics\n",
        "n = con.execute(\"SELECT COUNT(*) FROM univ_cs_from2015_papers\").fetchone()[0]\n",
        "print(f\"âœ“ Created and exported univ_cs_from2015_papers: {n:,} rows\")\n",
        "print(f\"ðŸ’¾ Saved: {OUT}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "sciscinet",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
